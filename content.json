{"pages":[{"title":"About Me","text":"Hi, there. I am Yanpeng Tong, currently a fresh graduate in the school of computer science and technology, Faculty of Computing, HIT. And it’s my great honor to join the Sentiment Computing(SC) group, Research Center for Social Computing and Information Retrieval (SCIR) in 2022 Fall, starting my M.S. Degree journey. InformationEmail: yptong@ir.hit.edu.cn or yanpengt06@gmail.com Github: github.com/yanpengt06 Home Page: yanpengt06.github.io/about I am supervised by Associate Professor Yanyan Zhao， and co-directed by Prof. Bing Qin. EducationB.S. Software Engineer, Faculty of Computing, HIT 2019.08 - 2023.06 M.S. Affective Computing, SCIR, Faculty of Computing, HIT 2023.09 - Present Research Interests Natural Language Process Affective Computing Empathetic Dialogue Web Service Development Awards Outstanding Undergraduate of HeiLongJiang Province, 2023.06 The First Prize on National College Student Information Security Contest(CISCN), 2022.08 National Scholarship, 2022.10 KuangHua Scholarship, 2020. The Third Prize in National Academic English Vocabulary Competition(NAEV), 2021. The People Scholarship, five times. Publications Yanpeng Tong, Xin Lu, Zhuojun Li, Yanyan Zhao and Bing Qin. HIT-SCIR at WASSA 2023: Empathy and Emotion Analysis at the Utterance-Level and the Essay-Level. Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis 2023(WASSA 2023). Zhao W, Zhao Y, Lu X, Tong Y, et al. Is ChatGPT Equipped with Emotional Dialogue Capabilities?[J]. arXiv preprint arXiv:2304.09582, 2023.[pdf] 钱泽凯,童彦澎,刘绍辉等.一种基于MAE人脸隐私保护方法的身份认证系统[J].网络安全与数据治理,2023,42(01):15-22+30.DOI:10.19358/j.issn.2097-1788.2023.01.002.[pdf] Research Experience Sentiment Computing(SC) Group, SCIR, 2021.09 - present Reinforcement Learning Based Join Order Selection, Massive Data Research Center(MDC), 2022.03 - 2022.04 Projects MAE-based Face Privacy Protection System, 2022.04 demo: http://mae.zkabout.xyz:8501 PS: it may not work all the time, the server may be used for other purpose (⊙﹏⊙) The Invoice Management System, 2022.01 Analysis and Prediction about COVID-19, Mathematical Modeling Competition in Northeastern China, 2020.06 “i-Bin“ Intelligent Classification Trash Can, 2020.09 InternshipiFlyTek, Research Institute of the Northeastern Asia, 2022.07 - 2022.12 HobbyMusic, Badminton, Piano, Movie. last updated: 2023-07-18","link":"/about/index.html"}],"posts":[{"title":"first try","text":"hexo搭建个人博客，mark一下","link":"/2022/06/19/first-try/"},{"title":"about course","text":"关于大三课程写在前面挺多学弟学妹咨询专业分流相关问题的，提前了解大三的课程内容也能帮助自己选到一个适合自己的专业方向，上一年自己不适合自己的专业也挺窒息的。HIT的有些课程名真的很迷，和教学内容差异巨大，不能”顾名思义“。为此将我所了解到的一些专业课程（仅罗列各方向专业核心课）主要内容罗列如下，希望对各位有帮助。 软件工程软件工程专业每学期有两门专业课，其中选一门作为4.5学分考试课，另一门3学分专业选修，外专业课可以选商务类mooc，大四需要实习至少三个月。 大三上 软件过程与工具 和名字差不多，从软件需求分析开始讲到系统设计，最后到系统实现，大概就是软件的生命周期和一些迭代方案。内容都相当古老，用的工具也就是所谓的git，starUML画类图。大概五六个实验，然后一个持续检查的大作业：从需求分析开始做一个完整的进销存系统。可以做PC端APP也可以做成web服务，大部分都是做成web服务，这个实际的开发和上课讲的毫无关系，上课不会教开发技术，如果没有web开发（前后端）的基础会比较吃力。理论内容都不难理解，考试闭卷，很偏概念，考的很细，可以背PPT速成，没记住就填不上的那种。 移动互联网技术 移动通信网络+万维网。前一半和计网通信那部分有重叠，后一半主要关注移动端侧web服务的开发，有涉及鸿蒙开发、UI交互、移动端存储等等。这课通信占比较大，讲了很多移动接入技术：WLAN,WPAN,WMAN等等。选这个做考试课实验好像是完整做出来一个移动端的应用就可以，选修交一个报告，参加期末考试就行，选修无实验。这课涉及的内容实在太多，考试也只考一些最基本的概念，选择题和上课小测题强相关，大三课基本都是答得差不多就给分，老师给分挺高的。 大三下 软件架构与中间件 顾名思义，讲软件的一些架构风格和中间件的介绍。从计算层（提高单机和集群的计算性能），数据层（提高数据服务器的性能），表示层（UI）展开。这课介绍的理论技术是比较新的了，负载均衡、分库分表、消息中间件这种都是企业必备。也算是入门性的讲解，实验大多也都是入门体验性质的，没有开发类型的实验。考试一面（一面A4，非一纸）开卷，你打印的东西越多，考试的难度就越低，选择题全是课堂习题，实测两天速成无压力。 数字媒体技术 最最最迷惑的专业，听上去很像做动画，3D渲染，视频特效的吧。都不是，可以理解成正统CV。两个老师上课。前一半内容基本上是传统CV，从信号开始讲起，带点信息论，包括傅里叶变换，图像变换，图像压缩，就这几个名词，足以让PPT看到头皮发麻。后一半内容正统机器学习，包括不限于：PCA，SVM等各种分类器，决策树，SIFT算子，深度学习，深度学习的攻防。如果选机器学习，这课相当于基本上过一半了就不太难。考试也不难，二纸开卷，深度学习部分都很基础，前一半看起来也不太难？我是瞎写的，前一半没怎么看，不确定。选修也需要做两个实验，一个是做图像的DCT等变换，BMP位图格式，第二个是用ResNet（CV深度学习模型）做MNIST数字手写体分类。必修好像还多几个实验。个人感觉这课放软工不太合适，一点也不工程，很科学。 自然语言处理我选修都是往这方向选修的，也涉及过一些课程。 自然语言处理。两个老师，前一半讲基于统计的自然语言处理，可以理解为深度学习兴起之前，包括不限于：分词，隐马尔可夫模型，最大熵模型。后一半讲基于深度学习的自然语言处理，全是介绍性的，都讲得不深，基本没什么深度学习方法。好像选修考试占比是80，记不太清了。必修实验有一个是按性能相对排名评分的。 信息检索。这个好理解，没选修过，略过。 智能信息处理这专业大三上学NLP专业课（自然语言处理），大三下学CV专业课 模式识别与深度学习 左老师的课，选的人很多。两个老师，前一半传统模式识别理论，与机器学习关系挺大的，学习一定程度上也是在做模式识别。后半部分是左老师的深度学习。从NN开始讲，然后从CV方向展开，基本能把CV整个发展进程的模型都梳理一遍。讲的内容挺深的，需要一定基础，会涉及很多近年的paper。选修考试占80分，必修的实验是模式识别一个，深度学习六个好像：自己复现MLP,CNN,RNN,GAN等 最后其他方向的课程也都是听说，不大清楚实际内容，建议咨询相关方向的学长学姐。以上内容尽量陈述事实，不包括对任何教师的主观评价。最后祝大家都能选到自己心仪的、适合自己的专业~~","link":"/2022/06/20/about-course/"},{"title":"A Survey on Sentiment Analysis","text":"情感分析综述：方法、应用与未来 情感分析的尺度 情感分析(Sentiment Analysis, SA)，在NLP领域特指文本情感分析，即分析文本所蕴含说话人想要表达的情感。尺度由小至大依次是方面（Aspect，翻译可能不当，下文仍采用英文）级、短语级、句子级以及文档级的情感分析，以下分类阐述。 文档级SA为整篇文档分配单一情感极性，在该尺度上进行分析通常较少。跨领域、跨语言是在该尺度上开展的重要任务，特定领域的SA已经取得了较高的准确率，但是特征向量也会因为领域之间的差异性而难以迁移。 句子级SA可聚合从而决定文档的情感极性。在先前工作中，句子级SA被用来寻找主观句；在较为复杂的任务，例如分析有歧义的语句以及条件句，语句级别的SA也是必不可少的。 短语级SA每一个短语可能包含多个aspect或者一个aspect，从而蕴含着相应的情感极性。一个比较有趣的是用来表达情感的短语，具有一定的群体特征（性别、年龄、种族），也十分值得挖掘。 方面(Aspect)级SA类似地，Aspect的情感极性可以聚集，从而决定一个句子的情感极性。举个例子：这个相机价格有点高，但是拍出来的照片质量很好！这个主观句包含一个对象的两个方面（Aspect），一个描述方面是相机的价格，贬义；另一个是相机的拍照质量，褒义，从一些介词副词可以分析出大体上语句仍是褒义的。 情感分析的Workflow 数据收集与特征选择 数据收集 ​ 互联网各类应用兴起后，数据可以说是海量的，来源广泛、良莠不齐。主要来源包括但不限于：网页，社交媒体，新闻及评论，电商网站，论坛，博客…… 特征选择 ​ 对于分类任务，特征的选择至关重要。一些可以参考的特征：Uni-gram, Bi-gram, …由于主观语句的特殊性，还可能包含标点信息以及Emoji表情信息，俚语信息等。 特征抽取 ​ 与特征选择概念上边界模糊，经常抽取的特征包括不限于：词频（TF-IDF），POS（Parts of Speech, 词性）标记，否定词（否定词对于情感分析至关重要，但有时他们会在停用词表里，或者在情感词典中是中性词而不对句子极性造成影响，实则不然，要视情况处理）以及BOS(Bag of Words)特征。 ​ 词向量也是对文本特征的一个抽取，无论是静态词向量又或是动态的词向量（自ELMO起），所蕴含的特征都较为丰富，富含语义信息。 特征再选择 ​ 经过抽取后的特征可能是重要的、不重要的、冗余的，因此需要进一步选择（不同于2中的选择，那个更倾向于抽取）。主要方法包括基于词典与统计方法。 a) 情感词典是由WordNet数据库构造而来，其中的每一项都对应一个数值，表示情感极性（例如越高越积极）。主要缺陷就是需要大量人力标注及专家知识，且人对于情感的标注具有主观性。 b) 统计方法主要包括四类： 过滤方法：不采用任何机器学习技术，仅依据统计指标，排序靠前的特征则被选择，主要指标有信息增益、互信息等，计算开销小。 Wrapper（包装？）方法：基于机器学习算法的输出，计算开销较大，可以确定最优特征子集，主要基于朴素贝叶斯、SVM等机器学习算法 嵌入方法：将特征选择过程包含在模型算法的执行过程之中，主要基于一些决策树算法，个人理解是通过剪枝从而完成特征选择，实现特征向量嵌入到一个低维子空间，因此叫嵌入方法？ 混合方法：结合上述多种方法。 情感分析的主要任务及必要性 主观句识别常被认为是SA的第一阶段任务，从文本中抽取出带有主观情感的语句。 情感分类是情感分析的一个主要任务，包括情感极性的分类（积极，消极，中性等）以及跨语言、跨领域情感分类等子任务。词的情感具有二义性是主要困难之一，即情感也由上下文决定。”这个相机的价格好高“与”这个相机的像素好高“中的”高“具有情感的二义性。值得一提的是，情感计算(Affective Computing)与情感分析也常作为其他系统的一个子系统使用，具有重要价值。 垃圾观点检测 许多主观评论可能由机器生成，例如评论水军，这类评论被称为垃圾评论，若不剔除会对情感分析的最终结果有较大干扰。机器学习算法是主流方法，常用方法还有：引入商品打分信息，评论用户的IP、打分偏好等信息，以及一些常识知识等其他信息。 隐式情感分析反讽、幽默常被称作隐式情感，这些模糊、隐晦的表达使得情感分析任务变得更加困难，是情感分析的一个具有挑战性的子任务。经典的方法有引入emoji，标点符号等信息，辅助判断。一个讽刺的例句： “Brilliant, I am fired!” Brilliant作为积极词汇在讽刺语句中起到了加强消极极性的作用。 Aspect抽取方面级的SA主要由aspect抽取，极性分类，极性聚集三个步骤组成。 aspect抽取的主要方法包括采用预定义集合，基于频率，基于语法，监督和无监督机器学习方法。以上方法各有优劣且互补。 必要性情感分析因其应用广泛而具有充分的研究必要性，也是近年来的一个热门研究领域。其常见的应用有： 经济 商品评论分析，客户满意度分析从而促进商品不断迭代 对用户的喜好建模，也可以被推荐系统所用，构建更加智能的推荐系统 产品公关，通过分析关于品牌的讨论、舆情，制定相应的策略。 股价预测：类似舆情分析，关于股市的舆情，进而预测股价、比特币等价格。 涉及的技术包括但不限于细粒度情感分析，aspect-level情感分析，评论摘要的生成。 政治：对于热点事件，分析国民情绪（舆情分析）对于社会治理有重要作用。 医疗健康 当下，精神类问题、疾病所占的比重日益增大， 从情感、心理学层面进行预防及治疗可以有效解决精神健康问题。 普通医疗方面情感分析可用于监测病人的状况，确定病人的需求。 情感分析的方法概述基于词典的方法如前文所述，情感词典是一些token的集合，每一个token被分配了一个数值以表示情感极性。基于词典方法的优势主要有无需训练数据，被视为是一种无监督方法；缺点也因此而产生，词典的构造需要专家知识，耗费人力物力且具有高度的领域相关性，在领域之间的迁移性极差。主要有两种基于词典的方法：基于语料库的方法与基于字典方法，下面分别阐述。 a) 基于语料库的方法 该方法考虑语义及语法模式来确定一个句子的极性。该方法首先预定义一个情感词术语集合及其极性，然后在巨大语料库中根据语法pattern，来发现情感词及其对应极性。前人的一些工作包括：利用了AND这类关联词所在两侧情感极性往往相同，即”情感一致性“等。 基于语料库的方法有两种类型：统计方法和语义方法 统计方法 种子观点词与上文所述的共现Pattern可以通过统计方法获得。主要思想是： 经常出现在积极语句中的词语本身有更大的可能是积极的。主要方法是：若某些token经常在相同的语境中出现，他们往往具有相同的极性。一个比较有趣的是，基于共现的统计方法可以用来检测虚假评论：评论的写作风格正常情况下应该是随机的，而不应该具有某种pattern，若不然，则很大可能是同一个用户批量撰写的虚假评论。 另一个统计方法是LSA，即隐语义分析。 语义方法 ​ 通过计算词语之间的相似性完成情感极性的判定：同义词往往有相同极性，反之。 b) 基于字典的方法 基于字典的方法包含一系列人工收集的预定义观点词集合。主要假设仍是同义词往往具有相同的情感极性，依据此不断扩充这个Opinion Word 的集合。 基于词典的两种方法优劣如下图所示： 机器学习方法本质上也是做特征提取和表示学习，用深度学习的方法做表示学习，具有高准确率、拟合能力强等特点。采用ML方法可以更好地理解上下文信息，完成反讽识别等较为复杂的情感分类任务。下面是一些常用的机器学习方法在SA领域的应用。 Naive Bayes 概率分类器，基于贝叶斯理论，建立在特征提取之后。 SVM 有监督学习分类器，习得参数只取决于支持向量，十分高效且鲁棒。 Logistic Regression(LR) 运用在分类任务上的概率回归模型，是一种线性分类器。 决策树与随机森林 通过样本基于一些指标（互信息等）学习最优决策属性，也十分高效。 最大熵模型 条件指数分类器，是一种基于特征函数学习权重的分类器，关键在特征函数的构造，往往也需要特征工程。 KNN 基于投票的分类器，在SA领域运用得不广泛，若经过恰当的训练，能取得不错的效果。 半监督学习 训练集包含标注数据与部分未标注数据，在现实中较多场景符合此情景。、 注：上述方法大部分均建立在 特征提取之后，好的特征对分类好坏至关重要，至于如何提取特征，如前所述或是用深度学习方法做表示学习都可能有不错的效果。 混合方法顾名思义，结合机器学习与词典的方法，取长补短，往往有不错的效果。 深度学习方法神经网络大火之后，用深度学习做表示学习在效率、效果上都远高于传统机器学习及基于词典的方法，各类网络架构在SA得到广泛应用，在各大任务上均有所突破，不详述，具体的一些应用如下表所示： 其他方法a) Aspect-based Sentiment Analysis(ABSA) ABSA是一个有价值且近年较热门的一个情感分析方向。包括三个阶段：aspect检测，极性分类以及极性聚集。该方法被广泛运用于文本评论分析中，举个例子： The food was awesome, but service was slow. Aspects可以有显式以及隐式两种定义方式，比如预先定义Implicit Aspect A= { taste, food }。那么上述例句的两个aspect分别是taste与service，情感极性分别为：积极，消极。那么简单地情感极性聚集后，该评论为中性评论，当然也可以有其他情感metric的定义方式。 b) 迁移学习 预训练-精调已成为NLP任务的新范式，迁移学习也能很好地应用在SA领域，经过精调后即可将SA任务从一个特定领域迁移到另一个领域，完成Cross-field。 多模态情感分析（Multimodal Sentiment Analysis）多模态为SA任务增加了一个level。主要模态包括：音频，图像。音调及表情可作为额外的信息辅助SA任务。MSA任务主要关注特征融合过程的设计，包括但不限于：基于注意力的模型，基于张量的模型。 评测指标常用的指标包括但不限于：P, R, F1 value, Accuracy, Specificity, TF-IDF等 挑战与未来 文体不正式带来的计算开销大 需要处理各个语言场景下的情感分析 传统方法难以分析隐式情感 标注成本高，需要低资源场景下的方法 大模型计算开销高 Cross-domain问题 程度副词的处理（slightly, barely, really） 混合语种语句难以处理 语言的更迭快（时空上皆有变化） 按照数据是否结构化的分类如下图所示： 小结 本文是对综述^[1]^的一个小结，情感分析是NLP一个较为热门的子领域：不完全统计^[2]^，近五年（2018-2022）共收录相关论文297篇，上方两张图也能阐明了近年领域研究的一些热门方向：情感对话，让人机对话更关注人的情绪，具有一定共情能力；多模态情感分析，利用各类模态信息进一步提升情感分析的准确性；反讽、隐喻等隐式情感分析一类较困难的任务；与精神健康、心理疾病检测相关的情感分析这一逐渐重视的研究方向；一些立场检测、辩论相关工作。以及一些重要的研究方法：基于预训练的迁移学习，多任务学习，少样本学习，引入外部知识等。 Reference[1] Wankhade M, Rao A C S, Kulkarni C. A survey on sentiment analysis methods, applications, and challenges[J]. Artificial Intelligence Review, 2022: 1-50. [2] 仅统计NAACL, ACL, EMNLP, COLING近五年主会（长短文）及findings，代码","link":"/2022/08/05/A-Survey-on-Sentiment-Analysis/"},{"title":"A Survey on Prompts-based Learning","text":"the prompts-method can be structured this way: Pre-trained Models Selectiontwo main training objectives Autoregressive fashion LM denoising objectives –&gt; loss over only noised parts or all parts different objectives suit for different downstream tasks. four paradigms of PTMs in prefix LM, encoder and decoder share params and encoder often adpots coruptions with according objective. Prompt EngineeringPrompt shape cloze prompts prefix prompts Manual Template Engineering LAMA dataset provides cloze templates Brown et create prefix prompts Automated Template LearningDiscrete Prompts(hard prompts)Some methods are as below: Prompt mining: scrape a large text corpus(Wiki) for strings containing [x] and [y], find middle words or dependency paths as prompts Prompt Paraphrasing: paraphrase seed prompts into a set Gradient-based Search: search over actual tokens Prompt Generation: use standard generation model Prompt Scoring: use unidirectional LM to score prompts Continuous Prompts(soft prompts)motivation: it’s not necessary to limit the prompt to human-interpretable language some methods are as below: Prefix Tuning: tune task-specific vectors Tuning initialized with discrete prompts: initialize with discrete prompts and then finue-tune the embeddings. hard-soft prompt hybrid tuning: insert tunable embeddings into a hard prompt template Answer EngineeringAnswer Shape tokens span sentence Design the Map From Answer Space to Output SpaceManual Design Unconstrained Spaces: identity map Constrained Spaces: map between answer and the underlying class Discrete Answer Search answer paraphrasing: expand answer space to broaden its coverage label decomposition: decompose label into constituent words Continuous Answer Searchassign a virtual token for each class label Multi-Prompt Learninguse multi-prompt can improve model’s performance further Prompt Ensembling Uniform average: take the average of probabilities from different prompts Weighted average: the weights are pre-specified or optimized over training-set Majority voting: for classification tasks Knowledge Distillation Prompt ensembling for text generation Prompt Augmentationalso called demo learning, which is prefixing a few examples to the prompt. These few-shot demos take advantage of the ability of LM to learn repetitive patterns Sample Selectiondifferent samples can result in quite different performance(ranging from SOTA to near random guess) Sentence Embeddings to sample examples close to the input provide positive samples and negative samples Sample Orderingsample order is quite important also entropy-based methods search and learn a separator token retrieval-based methods(add more context) Prompt Compositionuse sub-prompts to compose a prompt Prompt Decompositionbreak down the holistic prompt into sub-prompts Training Strategies for Prompting MethodsTraining Settings zero-shot few-shot full-data Update methodsthere are five tuning strategies refered Promptless fine-tuning Ad: no need for prompt design Disad: overfit and catastropic forget tuning-free prompting also called in-context learning, typical examples of tuning-free prompting include LAMA and GPT-3 Ad: efficiency and no catastrophic forgetting Disad: heavy engineering is needed, test-time can be long fixed-LM Prompt Tuning typical examples are prefix-tuning and WARP Ad: retain knowledge in LMs, suitable for few-shot settings Disad: prompts are usually no human-interpretable fixed-promp LM Tuning Prompt+LM Tuning Ad: most expressive method, can provide bootstrapping at the start of model training Disad: overfit small datasets ResourcesDataset Promptsexisting commonly-used prompts designed manually Prompt-relevant TopicsEnsemble LearningPrompt ensembling becomes another way to generate multiple results to be combined withou traning the model multiple times Few-shot LearningPrompt Augmentation can be viewed as a way to few-shot learning, which elicit knowledge from LMs explicitly It’s also related to large-context learning Query Reformulationelicit more relevant texts by expanding query with related query terms LM can be viewed as a kind of query, but the knowledge bases are a black-box ConcludeThe timeline of researchs on Prompt-based learning can be found here. This blog is a summary on Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing, a very beginner-friendly material for the start of prompts-bsaed learning.","link":"/2022/11/28/prompt/"}],"tags":[{"name":"Sentiment Analysis","slug":"Sentiment-Analysis","link":"/tags/Sentiment-Analysis/"},{"name":"HIT","slug":"HIT","link":"/tags/HIT/"},{"name":"Prompt","slug":"Prompt","link":"/tags/Prompt/"}],"categories":[]}